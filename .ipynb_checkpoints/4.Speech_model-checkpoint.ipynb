{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine prf models with category-selective model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals.\n",
    "\n",
    "Make new design matrices, conditioned on the presence of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tank/hedger/software/hcp_movie/cfhcpy/base.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/tank/hedger/software/hcp_movie/cfhcpy/fit_utils.py:22: UserWarning: \n",
      "\n",
      " | Using Nistats with Nilearn versions >= 0.7.0 is redundant and potentially conflicting.\n",
      " | Nilearn versions 0.7.0 and up offer all the functionality of Nistats as well the latest features and fixes.\n",
      " | We strongly recommend uninstalling Nistats and using Nilearn's stats & reporting modules.\n",
      "\n",
      "  from nistats.hemodynamic_models import spm_hrf\n",
      "/tank/hedger/software/anaconda3/envs/p3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cortex\n",
    "import h5py\n",
    "from funcs import h5_make\n",
    "\n",
    "from cfhcpy.base import AnalysisBase\n",
    "from funcs import HCP_subject\n",
    "late = AnalysisBase()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prfpy.stimulus import PRFStimulus1Dn\n",
    "from prfpy.model import Iso1DGaussianModel\n",
    "from prfpy.model import CSS_Iso1DGaussianModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename already exists\n"
     ]
    }
   ],
   "source": [
    "h5path='/tank/hedger/DATA/HCP_temp/OUTPUTS/h5' # Path for outputting hdf5 files. \n",
    "f=h5_make(h5path,'overlays')\n",
    "data = h5py.File(f, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of subject late on romulus with settings \n",
      "{\n",
      " \"identifier\": \"node230\",\n",
      " \"base_dir\": \"/scratch/2019/visual/hcp_{experiment}/\",\n",
      " \"code_dir\": \"/tank/hedger/scripts/HCP_tonotopy\",\n",
      " \"threads\": 40\n",
      "}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt : After ref date? 1=True or 0=False 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.69s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating design matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/921 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 921/921 [00:00<00:00, 7036.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/921 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 921/921 [00:00<00:00, 7059.35it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.67s/it]\n",
      "  0%|          | 0/918 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 918/918 [00:00<00:00, 7203.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/918 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 918/918 [00:00<00:00, 7162.59it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:05<00:05,  2.66s/it]\n",
      "  0%|          | 0/915 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 915/915 [00:00<00:00, 7213.26it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/915 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 915/915 [00:00<00:00, 7126.00it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.66s/it]\n",
      "  0%|          | 0/901 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 901/901 [00:00<00:00, 7105.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/901 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 901/901 [00:00<00:00, 7287.27it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.64s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making training and test folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "late = AnalysisBase()\n",
    "\n",
    "late.startup(subject='late', experiment_id='movie', yaml_file='/tank/hedger/software/hcp_movie/config.yml')\n",
    "\n",
    "\n",
    "late.subject_base_dir='/tank/hedger/DATA/HCP_temp/late'\n",
    "\n",
    "latesub=HCP_subject(late)\n",
    "\n",
    "latesub.prep_data()\n",
    "\n",
    "dtype='main' # Use the independent data, thereby chopping off the 'test sequence'\n",
    "standardise=True # Standardise the design matrix\n",
    "zaxis=1\n",
    "filt=False # Dont filter the design matrix,we will filter the predictions instead.\n",
    "\n",
    "latesub.import_data(dtype,standardise,filt,zaxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for making speech design matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from funcs import convolve, create_hrf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def make_speech_dm(fold,cut=True):\n",
    "    \n",
    "    mylist=sorted(os.listdir('/tank/hedger/DATA/HCP_temp/Resources/captions'))\n",
    "    \n",
    "    frame=pd.read_csv(os.path.join('/tank/hedger/DATA/HCP_temp/Resources/captions',mylist[fold]),delimiter=';')\n",
    "    frame['Startsecs']=frame['Start time in milliseconds']/1000\n",
    "    frame['Endsecs']=frame['End time in milliseconds']/1000\n",
    "    starts=np.array(frame['Startsecs'].astype(int))\n",
    "    ends=np.array(frame['Endsecs'].astype(int))\n",
    "    empty=np.zeros(latesub.ab.experiment_dict['run_durations'][fold])\n",
    "    for i in range(starts.shape[0]):\n",
    "        empty[starts[i]:ends[i]]=1\n",
    "    if cut:\n",
    "        empty=empty[:-latesub.ab.experiment_dict['test_duration']]\n",
    "    other=1-empty\n",
    "    other[latesub.dm_test[fold][0]==0]=0\n",
    "        \n",
    "    return empty,other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each test dataset, construct the speech and nonspeech design matrices, append into the same fold combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def make_speech_dms(sub):\n",
    "    \n",
    "    speechdms_train,nspeechdms_train=[],[]\n",
    "    speechdms_test,nspeechdms_test=[],[]\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        dmtrain=np.hstack([make_speech_dm(t) for t in sub.folds[i]])\n",
    "        dmtest=make_speech_dm(i)\n",
    "    \n",
    "        tempsp_train,tempnsp_train=np.copy(sub.dm_train[i]),np.copy(sub.dm_train[i])\n",
    "    \n",
    "        tempsp_test,tempnsp_test=np.copy(sub.dm_test[i]),np.copy(sub.dm_test[i])\n",
    "    \n",
    "        tempsp_train[:,dmtrain[0]==0]=0\n",
    "        tempnsp_train[:,dmtrain[1]==0]=0\n",
    "    \n",
    "        tempsp_test[:,dmtest[0]==0]=0\n",
    "        tempnsp_test[:,dmtest[1]==0]=0\n",
    "    \n",
    "    \n",
    "        speechdms_train.append(tempsp_train)\n",
    "        nspeechdms_train.append(tempnsp_train)\n",
    "    \n",
    "        speechdms_test.append(tempsp_test)\n",
    "        nspeechdms_test.append(tempnsp_test)\n",
    "        \n",
    "    sub.speechdms_train=speechdms_train\n",
    "    sub.nspeechdms_train=nspeechdms_train\n",
    "    sub.speechdms_test=speechdms_test\n",
    "    sub.nspeechdms_test=nspeechdms_test\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_speech_dms(latesub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the CSS parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename already exists\n",
      "filename already exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "frame=pd.read_csv('/tank/hedger/DATA/HCP_temp/OUTPUTS/CSVS/sframe.csv')\n",
    "mask=np.array(frame['mask'])\n",
    "nvertices=mask.shape[0]\n",
    "\n",
    "late=h5_make('/tank/hedger/DATA/HCP_temp/late','AUDITORY_FITS_CSS_FULL')\n",
    "latef = h5py.File(late, \"r\")\n",
    "latef.keys()\n",
    "late_foldp=np.array(latef['ub_log_fold_params_CSS'])\n",
    "\n",
    "\n",
    "early=h5_make('/tank/hedger/DATA/HCP_temp/early','AUDITORY_FITS_CSS_FULL')\n",
    "earlyf = h5py.File(early, \"r\")\n",
    "earlyf.keys()\n",
    "early_foldp=np.array(earlyf['ub_log_fold_params_CSS'])\n",
    "\n",
    "\n",
    "late_xval=np.array(latef['ub_log_fold_xval_CSS'])\n",
    "early_xval=np.array(earlyf['ub_log_fold_xval_CSS'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_foldp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latef.close()\n",
    "earlyf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pred(tseries_raw,speechpred,nspeechpred,betas):\n",
    "    yhat=betas[-1]+(speechpred*betas[0])+(nspeechpred*betas[1])\n",
    "    rsq = 1-(yhat-tseries_raw).var(0)/tseries_raw.var(0)\n",
    "    return yhat,rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_vert(data,mask):\n",
    "    vdat=np.repeat(0,mask.shape[-1]).astype('float32')\n",
    "    vdat[mask==1]=np.array(data)\n",
    "    return vdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_speech_model(sub,mask,fold,foldp,log=True):\n",
    "    \n",
    "    indices=np.where(mask==1)[0]\n",
    "    blengths=np.array(sub.ab.experiment_dict['run_durations'])[np.array(sub.folds[fold])]-sub.ab.experiment_dict['test_duration']\n",
    "    blockarr=np.repeat(sub.folds[fold],blengths)\n",
    "    if log==True:\n",
    "        frequencies=np.log(sub.frequencies)\n",
    "        \n",
    "    # Make auditory stimulus\n",
    "    speechstim_train=PRFStimulus1Dn(sub.speechdms_train[fold],frequencies,TR=1,block_inds=blockarr)\n",
    "    nspeechstim_train=PRFStimulus1Dn(sub.nspeechdms_train[fold],frequencies,TR=1,block_inds=blockarr)\n",
    "    speechstim_test=PRFStimulus1Dn(sub.speechdms_test[fold],frequencies,TR=1)\n",
    "    nspeechstim_test=PRFStimulus1Dn(sub.nspeechdms_test[fold],frequencies,TR=1)\n",
    "\n",
    "\n",
    "    fparams = {\"window_length\":201,\"polyorder\": 3}\n",
    "\n",
    "    # Make auditory models.\n",
    "    speechmod_train=CSS_Iso1DGaussianModel(speechstim_train,normalise_RFs=False,filter_predictions=True,filter_type='sg',filter_params=fparams)\n",
    "    speechmod_train.func='cart'\n",
    "\n",
    "    nspeechmod_train=CSS_Iso1DGaussianModel(nspeechstim_train,normalise_RFs=False,filter_predictions=True,filter_type='sg',filter_params=fparams)\n",
    "    nspeechmod_train.func='cart'\n",
    "\n",
    "    speechmod_test=CSS_Iso1DGaussianModel(speechstim_test,normalise_RFs=False,filter_predictions=True,filter_type='sg',filter_params=fparams)\n",
    "    speechmod_test.func='cart'\n",
    "\n",
    "    nspeechmod_test=CSS_Iso1DGaussianModel(nspeechstim_test,normalise_RFs=False,filter_predictions=True,filter_type='sg',filter_params=fparams)\n",
    "    nspeechmod_test.func='cart'\n",
    "\n",
    "    # Make predictions based on current model. \n",
    "    speechpreds=[speechmod_train.return_prediction(*list(foldp[fold,index,:][:-1]))[0] for index in indices]\n",
    "    nspeechpreds=[nspeechmod_train.return_prediction(*list(foldp[fold,index,:][:-1]))[0] for index in indices]\n",
    "\n",
    "    speechpreds_test=[speechmod_test.return_prediction(*list(foldp[fold,index,:][:-1]))[0] for index in indices]\n",
    "    nspeechpreds_test=[nspeechmod_test.return_prediction(*list(foldp[fold,index,:][:-1]))[0] for index in indices]\n",
    "    \n",
    "    yhats,betass,rsqs=[],[],[]\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    # Now fit a model.\n",
    "    i=0\n",
    "    for index in tqdm(indices):\n",
    "        \n",
    "        # Make design matrix (speech, nspeech, intercept).\n",
    "        dm=np.vstack([speechpreds[i],nspeechpreds[i],np.repeat(1,nspeechpreds[i].shape)])\n",
    "        # Get the data\n",
    "        tseries_raw=sub.data_train[fold][:,index]\n",
    "        tseries_raw=np.nan_to_num(tseries_raw)\n",
    "        dm=np.nan_to_num(dm)\n",
    "        betas, _, _, _ = np.linalg.lstsq(dm.T, tseries_raw.T)\n",
    "        yhat = np.dot(betas.T, dm)\n",
    "        rsq = 1-(yhat-tseries_raw).var(0)/tseries_raw.var(0)\n",
    "    \n",
    "        rsqs.append(rsq)\n",
    "        yhats.append(yhat)\n",
    "        betass.append(betas)\n",
    "        i=i+1\n",
    "    \n",
    "    R2=masked_vert(np.array(rsqs),mask)\n",
    "\n",
    "    betas=np.array(betass)\n",
    "    \n",
    "    i=0\n",
    "    perf=[]\n",
    "    for index in tqdm(indices):\n",
    "        res=test_pred(sub.data_test[fold][:,index],speechpreds_test[i],nspeechpreds_test[i],betass[i])\n",
    "        perf.append(res[1])\n",
    "        i=i+1\n",
    "        \n",
    "    xval=masked_vert(np.array(perf),mask)\n",
    "    \n",
    "\n",
    "    return R2,xval,betas \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-11-e6a8af5a2d22>:7: RuntimeWarning: divide by zero encountered in log\n",
      "  frequencies=np.log(sub.frequencies)\n",
      "/tank/hedger/software/prfpy/prfpy/model.py:814: RuntimeWarning: divide by zero encountered in power\n",
      "  neural_tc = stimulus_through_prf(rf, dm, 1)**n\n",
      "/tank/hedger/software/anaconda3/envs/p3/lib/python3.8/site-packages/scipy/signal/signaltools.py:381: RuntimeWarning: invalid value encountered in multiply\n",
      "  ret = ifft(sp1 * sp2, fshape, axes=axes)\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A<ipython-input-11-e6a8af5a2d22>:51: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  betas, _, _, _ = np.linalg.lstsq(dm.T, tseries_raw.T)\n",
      "\n",
      "  4%|▍         | 153/3914 [00:00<00:02, 1521.80it/s]\u001b[A\n",
      " 12%|█▏        | 465/3914 [00:00<00:01, 1797.87it/s]\u001b[A\n",
      " 21%|██▏       | 838/3914 [00:00<00:01, 2128.61it/s]\u001b[A\n",
      " 31%|███       | 1209/3914 [00:00<00:01, 2440.08it/s]\u001b[A\n",
      " 40%|████      | 1583/3914 [00:00<00:00, 2723.52it/s]\u001b[A\n",
      " 50%|████▉     | 1954/3914 [00:00<00:00, 2957.80it/s]\u001b[A\n",
      " 59%|█████▉    | 2325/3914 [00:00<00:00, 3148.47it/s]\u001b[A\n",
      " 69%|██████▉   | 2696/3914 [00:00<00:00, 3296.11it/s]\u001b[A\n",
      " 78%|███████▊  | 3066/3914 [00:00<00:00, 3406.86it/s]\u001b[A\n",
      " 88%|████████▊ | 3437/3914 [00:01<00:00, 3492.42it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3460.61it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23130.57it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [01:24<04:12, 84.19s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 157/3914 [00:00<00:02, 1561.30it/s]\u001b[A\n",
      " 12%|█▏        | 475/3914 [00:00<00:01, 1842.03it/s]\u001b[A\n",
      " 22%|██▏       | 856/3914 [00:00<00:01, 2179.53it/s]\u001b[A\n",
      " 32%|███▏      | 1241/3914 [00:00<00:01, 2504.98it/s]\u001b[A\n",
      " 41%|████▏     | 1615/3914 [00:00<00:00, 2778.91it/s]\u001b[A\n",
      " 51%|█████     | 1987/3914 [00:00<00:00, 3006.09it/s]\u001b[A\n",
      " 60%|██████    | 2353/3914 [00:00<00:00, 3174.77it/s]\u001b[A\n",
      " 70%|██████▉   | 2734/3914 [00:00<00:00, 3340.95it/s]\u001b[A\n",
      " 80%|███████▉  | 3116/3914 [00:00<00:00, 3470.75it/s]\u001b[A\n",
      " 89%|████████▉ | 3503/3914 [00:01<00:00, 3580.96it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3523.68it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23090.13it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [02:46<02:47, 83.72s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 155/3914 [00:00<00:02, 1546.90it/s]\u001b[A\n",
      " 12%|█▏        | 478/3914 [00:00<00:01, 1833.30it/s]\u001b[A\n",
      " 22%|██▏       | 855/3914 [00:00<00:01, 2167.18it/s]\u001b[A\n",
      " 32%|███▏      | 1237/3914 [00:00<00:01, 2489.52it/s]\u001b[A\n",
      " 41%|████▏     | 1621/3914 [00:00<00:00, 2782.83it/s]\u001b[A\n",
      " 51%|█████     | 1980/3914 [00:00<00:00, 2983.20it/s]\u001b[A\n",
      " 60%|██████    | 2356/3914 [00:00<00:00, 3178.94it/s]\u001b[A\n",
      " 70%|██████▉   | 2735/3914 [00:00<00:00, 3338.41it/s]\u001b[A\n",
      " 80%|███████▉  | 3119/3914 [00:00<00:00, 3473.99it/s]\u001b[A\n",
      " 89%|████████▉ | 3496/3914 [00:01<00:00, 3557.29it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3515.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 22324.99it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [04:11<01:23, 83.92s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 155/3914 [00:00<00:02, 1546.46it/s]\u001b[A\n",
      " 12%|█▏        | 473/3914 [00:00<00:01, 1827.99it/s]\u001b[A\n",
      " 22%|██▏       | 851/3914 [00:00<00:01, 2162.98it/s]\u001b[A\n",
      " 31%|███▏      | 1231/3914 [00:00<00:01, 2483.77it/s]\u001b[A\n",
      " 41%|████▏     | 1617/3914 [00:00<00:00, 2780.38it/s]\u001b[A\n",
      " 51%|█████     | 2003/3914 [00:00<00:00, 3033.49it/s]\u001b[A\n",
      " 61%|██████    | 2383/3914 [00:00<00:00, 3227.01it/s]\u001b[A\n",
      " 71%|███████   | 2761/3914 [00:00<00:00, 3373.79it/s]\u001b[A\n",
      " 80%|████████  | 3143/3914 [00:00<00:00, 3494.18it/s]\u001b[A\n",
      " 90%|████████▉ | 3519/3914 [00:01<00:00, 3567.88it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3532.40it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23295.84it/s]\u001b[A\n",
      "100%|██████████| 4/4 [05:34<00:00, 83.62s/it]\n"
     ]
    }
   ],
   "source": [
    "late_sms=[]\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    late_sms.append(fit_speech_model(latesub,mask,i,late_foldp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_diff=np.array([late_sms[i][1]-late_foldp[i,:,-1] for i in range(4)])\n",
    "late_sp_xval=np.array([late_sms[i][1] for i in range(4)])\n",
    "late_sp_betas=np.array([masked_vert(late_sms[i][2][:,0],mask) for i in range(4)])\n",
    "late_nsp_betas=np.array([masked_vert(late_sms[i][2][:,1],mask) for i in range(4)])\n",
    "late_intercepts=np.array([masked_vert(late_sms[i][2][:,2],mask) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ub_log_fold_intercepts'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funcs import h5_dump2\n",
    "\n",
    "late=h5_make('/tank/hedger/DATA/HCP_temp/late','AUDITORY_FITS_CSS_FULL')\n",
    "\n",
    "h5_dump2(late,late_diff,'ub_log_fold_sp_diff')\n",
    "h5_dump2(late,late_sp_xval,'ub_log_fold_sp_xval')\n",
    "h5_dump2(late,late_sp_betas,'ub_log_fold_sp_betas')\n",
    "h5_dump2(late,late_nsp_betas,'ub_log_fold_nsp_betas')\n",
    "h5_dump2(late,late_intercepts,'ub_log_fold_intercepts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of subject early on romulus with settings \n",
      "{\n",
      " \"identifier\": \"node230\",\n",
      " \"base_dir\": \"/scratch/2019/visual/hcp_{experiment}/\",\n",
      " \"code_dir\": \"/tank/hedger/scripts/HCP_tonotopy\",\n",
      " \"threads\": 40\n",
      "}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt : After ref date? 1=True or 0=False 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating design matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/921 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 921/921 [00:00<00:00, 7218.73it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/921 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 921/921 [00:00<00:00, 7274.13it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:02<00:07,  2.66s/it]\n",
      "  0%|          | 0/918 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 918/918 [00:00<00:00, 7174.12it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/918 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 918/918 [00:00<00:00, 7314.51it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:05<00:05,  2.64s/it]\n",
      "  0%|          | 0/915 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 915/915 [00:00<00:00, 7294.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/915 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 915/915 [00:00<00:00, 7314.43it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.63s/it]\n",
      "  0%|          | 0/901 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 901/901 [00:00<00:00, 7389.26it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/901 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 901/901 [00:00<00:00, 7344.83it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.60s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making training and test folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "early = AnalysisBase()\n",
    "\n",
    "early.startup(subject='early', experiment_id='movie', yaml_file='/tank/hedger/software/hcp_movie/config.yml')\n",
    "\n",
    "\n",
    "early.subject_base_dir='/tank/hedger/DATA/HCP_temp/early'\n",
    "\n",
    "earlysub=HCP_subject(early)\n",
    "\n",
    "earlysub.prep_data()\n",
    "\n",
    "dtype='main' # Use the independent data, thereby chopping off the 'test sequence'\n",
    "standardise=True # Standardise the design matrix\n",
    "zaxis=1\n",
    "filt=False # Dont filter the design matrix,we will filter the predictions instead.\n",
    "\n",
    "earlysub.import_data(dtype,standardise,filt,zaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_speech_dms(earlysub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-11-e6a8af5a2d22>:7: RuntimeWarning: divide by zero encountered in log\n",
      "  frequencies=np.log(sub.frequencies)\n",
      "/tank/hedger/software/prfpy/prfpy/model.py:814: RuntimeWarning: divide by zero encountered in power\n",
      "  neural_tc = stimulus_through_prf(rf, dm, 1)**n\n",
      "/tank/hedger/software/anaconda3/envs/p3/lib/python3.8/site-packages/scipy/signal/signaltools.py:381: RuntimeWarning: invalid value encountered in multiply\n",
      "  ret = ifft(sp1 * sp2, fshape, axes=axes)\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A<ipython-input-11-e6a8af5a2d22>:51: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  betas, _, _, _ = np.linalg.lstsq(dm.T, tseries_raw.T)\n",
      "\n",
      "  4%|▍         | 155/3914 [00:00<00:02, 1544.47it/s]\u001b[A\n",
      " 12%|█▏        | 473/3914 [00:00<00:01, 1825.53it/s]\u001b[A\n",
      " 22%|██▏       | 847/3914 [00:00<00:01, 2156.07it/s]\u001b[A\n",
      " 31%|███       | 1220/3914 [00:00<00:01, 2468.32it/s]\u001b[A\n",
      " 41%|████      | 1593/3914 [00:00<00:00, 2745.98it/s]\u001b[A\n",
      " 50%|█████     | 1970/3914 [00:00<00:00, 2989.09it/s]\u001b[A\n",
      " 60%|██████    | 2349/3914 [00:00<00:00, 3190.36it/s]\u001b[A\n",
      " 70%|██████▉   | 2728/3914 [00:00<00:00, 3348.58it/s]\u001b[A\n",
      " 79%|███████▉  | 3106/3914 [00:00<00:00, 3466.72it/s]\u001b[A\n",
      " 89%|████████▉ | 3480/3914 [00:01<00:00, 3542.06it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3492.99it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23130.70it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [01:25<04:15, 85.11s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 190/3914 [00:00<00:01, 1896.50it/s]\u001b[A\n",
      " 13%|█▎        | 500/3914 [00:00<00:01, 2146.36it/s]\u001b[A\n",
      " 22%|██▏       | 866/3914 [00:00<00:01, 2450.32it/s]\u001b[A\n",
      " 31%|███▏      | 1229/3914 [00:00<00:00, 2713.98it/s]\u001b[A\n",
      " 40%|████      | 1584/3914 [00:00<00:00, 2919.47it/s]\u001b[A\n",
      " 50%|█████     | 1963/3914 [00:00<00:00, 3134.60it/s]\u001b[A\n",
      " 60%|█████▉    | 2340/3914 [00:00<00:00, 3300.14it/s]\u001b[A\n",
      " 69%|██████▉   | 2719/3914 [00:00<00:00, 3432.87it/s]\u001b[A\n",
      " 79%|███████▉  | 3100/3914 [00:00<00:00, 3535.47it/s]\u001b[A\n",
      " 89%|████████▉ | 3480/3914 [00:01<00:00, 3609.90it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3500.86it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23044.79it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [02:52<02:51, 85.69s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 156/3914 [00:00<00:02, 1550.68it/s]\u001b[A\n",
      " 12%|█▏        | 477/3914 [00:00<00:01, 1834.94it/s]\u001b[A\n",
      " 22%|██▏       | 859/3914 [00:00<00:01, 2173.18it/s]\u001b[A\n",
      " 32%|███▏      | 1239/3914 [00:00<00:01, 2492.58it/s]\u001b[A\n",
      " 41%|████▏     | 1620/3914 [00:00<00:00, 2780.23it/s]\u001b[A\n",
      " 51%|█████     | 1997/3914 [00:00<00:00, 3016.36it/s]\u001b[A\n",
      " 61%|██████    | 2377/3914 [00:00<00:00, 3214.08it/s]\u001b[A\n",
      " 70%|███████   | 2756/3914 [00:00<00:00, 3367.39it/s]\u001b[A\n",
      " 80%|████████  | 3136/3914 [00:00<00:00, 3484.05it/s]\u001b[A\n",
      " 90%|████████▉ | 3516/3914 [00:01<00:00, 3571.54it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3532.52it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23751.90it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [04:18<01:25, 85.92s/it]\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 155/3914 [00:00<00:02, 1541.34it/s]\u001b[A\n",
      " 12%|█▏        | 477/3914 [00:00<00:01, 1826.84it/s]\u001b[A\n",
      " 22%|██▏       | 857/3914 [00:00<00:01, 2163.88it/s]\u001b[A\n",
      " 32%|███▏      | 1238/3914 [00:00<00:01, 2485.26it/s]\u001b[A\n",
      " 41%|████▏     | 1617/3914 [00:00<00:00, 2770.88it/s]\u001b[A\n",
      " 51%|█████     | 1996/3914 [00:00<00:00, 3012.56it/s]\u001b[A\n",
      " 61%|██████    | 2377/3914 [00:00<00:00, 3213.88it/s]\u001b[A\n",
      " 70%|███████   | 2757/3914 [00:00<00:00, 3369.71it/s]\u001b[A\n",
      " 80%|████████  | 3138/3914 [00:00<00:00, 3488.32it/s]\u001b[A\n",
      " 90%|████████▉ | 3518/3914 [00:01<00:00, 3574.43it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:01<00:00, 3534.87it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3914 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3914/3914 [00:00<00:00, 23638.32it/s]\u001b[A\n",
      "100%|██████████| 4/4 [05:41<00:00, 85.41s/it]\n"
     ]
    }
   ],
   "source": [
    "early_sms=[]\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    early_sms.append(fit_speech_model(earlysub,mask,i,early_foldp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_diff=np.array([early_sms[i][1]-early_foldp[i,:,-1] for i in range(4)])\n",
    "early_sp_xval=np.array([early_sms[i][1] for i in range(4)])\n",
    "early_sp_betas=np.array([masked_vert(early_sms[i][2][:,0],mask) for i in range(4)])\n",
    "early_nsp_betas=np.array([masked_vert(early_sms[i][2][:,1],mask) for i in range(4)])\n",
    "early_intercepts=np.array([masked_vert(early_sms[i][2][:,2],mask) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ub_log_fold_intercepts'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early=h5_make('/tank/hedger/DATA/HCP_temp/early','AUDITORY_FITS_CSS_FULL')\n",
    "\n",
    "h5_dump2(early,early_diff,'ub_log_fold_sp_diff')\n",
    "h5_dump2(early,early_sp_xval,'ub_log_fold_sp_xval')\n",
    "h5_dump2(early,early_sp_betas,'ub_log_fold_sp_betas')\n",
    "h5_dump2(early,early_nsp_betas,'ub_log_fold_nsp_betas')\n",
    "h5_dump2(early,early_intercepts,'ub_log_fold_intercepts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "latef.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
