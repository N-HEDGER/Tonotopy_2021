{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Subject averaging.\n",
    "\n",
    "## Goals:\n",
    "\n",
    "Subjects viewed two slightly different types of video as described in the HCP 12000 reference manual. Rather than averaging the data across all subjects, it is better to do due dilligence and average them depending on the specific video that they viewed (even if the differences are minor). \n",
    "\n",
    "This allows us to investigate the agreement of the parameters estimated from two across-subject folds.\n",
    "\n",
    "I want to determine which subject viewed what video, average accordingly and then save in the appropriate format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from funcs import HCP_subject\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import nibabel as nib\n",
    "import os\n",
    "import cifti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start an analysis base with an arbitrary subject, just so we have access to all the paths and other constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subno=114823\n",
    "expt_id='movie'\n",
    "yaml='/tank/hedger/scripts/Tonotopy_2021/config.yml'\n",
    "tempsub=HCP_subject(str(subno),experiment_id=expt_id,yaml_file=yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a cifti brain model for saving out the new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifti\n",
    "cifti_brain_model = cifti.read(os.path.join(tempsub.experiment_base_dir, tempsub.brainmodel_cifti_file))[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through all the subjects, use their CSV file to return the video they watched. Dump this in a list. Also get a list of functional files for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movtype=[]\n",
    "dpaths=[]\n",
    "\n",
    "for sub in tqdm(tempsub.full_data_subjects):\n",
    "    mysub=HCP_subject(str(sub),experiment_id=expt_id,yaml_file=yaml)\n",
    "    movtype.append(mysub.vidprefix)\n",
    "    mysub.get_data_paths()\n",
    "    dpaths.append(mysub.dpaths)\n",
    "    tbase=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of participants that viewed each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(movtype).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that most viewed the new video. Get the indices of the participants that viewed each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyvidsubs= [i for i, s in enumerate(movtype) if 'Pre_20140821' in s]\n",
    "latevidsubs= [i for i, s in enumerate(movtype) if 'Post_20140821' in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for reading in the data for a specific run/movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array(dpaths,s,movind):\n",
    "    data=nib.load(dpaths[s][movind])\n",
    "    darray=np.array(data.get_data())\n",
    "    return darray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to output the early and late subjects to different directories. Do this in my own space so as to not disrupt the original folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlydir=os.path.join(tempsub.agg_path,'early')\n",
    "latedir=os.path.join(tempsub.agg_path,'late')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preserve the same kind of filename so that all of the functionality will still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEDS=['AP','PA','PA','AP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for creating the mean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_data(dpaths,subs,movienum,outputdir,save):\n",
    "    \n",
    "    sub_readin=Parallel(n_jobs=20,verbose=1)(delayed(read_array)(dpaths,s,movienum)  for s in subs) #Read in all the data\n",
    "    sub_array=np.array(sub_readin) # Make into big array\n",
    "    sub_meandat=np.mean(sub_array,0) # Take mean.\n",
    "    \n",
    "    if save==True:\n",
    "        \n",
    "        tps=np.array(range(tempsub.experiment_dict['run_durations'][movienum])).astype('str') # The cifti writing seems to require us to give the number of timepoints\n",
    "        \n",
    "        fname=os.path.join(outputdir,'tfMRI_{experiment_id}{run}_{PED}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries_sg_psc.nii'.format(experiment_id='MOVIE',run=str(tempsub.experiment_dict['runs'][movienum]),PED=PEDS[movienum]))        \n",
    "        \n",
    "        cifti.write(fname, sub_meandat,(cifti.Scalar.from_names(tps),cifti_brain_model))\n",
    "    \n",
    "    return sub_meandat,fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break this task down and do it for each run. It is quite memory intensive given the size of the arrays we are reading in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,earlyvidsubs,0,earlydir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,earlyvidsubs,1,earlydir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,earlyvidsubs,2,earlydir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,earlyvidsubs,3,earlydir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,latevidsubs,0,latedir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,latevidsubs,1,latedir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,latevidsubs,2,latedir,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_mean_data(dpaths,latevidsubs,3,latedir,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also make splithalf averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import random_splithalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=random_splithalf(tempsub.full_data_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "splitpath1=os.path.join(tempsub.agg_path,'subsplit_{splitind}'.format(splitind=1))\n",
    "splitpath2=os.path.join(tempsub.agg_path,'subsplit_{splitind}'.format(splitind=2))\n",
    "os.makedirs(splitpath1,exist_ok=True)\n",
    "os.makedirs(splitpath2,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    x=create_mean_data(dpaths,a,i,splitpath1,True)\n",
    "    x=create_mean_data(dpaths,b,i,splitpath2,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
